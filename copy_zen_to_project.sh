#!/bin/bash

# copy_zen_to_project.sh - å°†Zen AIæ¨¡å‹é›†æˆå¤åˆ¶åˆ°ç›®æ ‡é¡¹ç›®
# ç”¨æ³•: ./copy_zen_to_project.sh <ç›®æ ‡é¡¹ç›®è·¯å¾„>

set -e

if [ $# -eq 0 ]; then
    echo "é”™è¯¯: è¯·æä¾›ç›®æ ‡é¡¹ç›®è·¯å¾„"
    echo "ç”¨æ³•: $0 <ç›®æ ‡é¡¹ç›®è·¯å¾„>"
    exit 1
fi

TARGET_DIR="$1"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

echo "ğŸ“‹ å¼€å§‹å¤åˆ¶Zen AIæ–‡ä»¶åˆ°é¡¹ç›®..."
echo "   æºç›®å½•: $SCRIPT_DIR"
echo "   ç›®æ ‡ç›®å½•: $TARGET_DIR"

# æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦å­˜åœ¨
if [ ! -d "$TARGET_DIR" ]; then
    echo "âŒ é”™è¯¯: ç›®æ ‡ç›®å½•ä¸å­˜åœ¨: $TARGET_DIR"
    exit 1
fi

# åˆ›å»ºzen_toolsç›®å½•
mkdir -p "$TARGET_DIR/zen_tools"

# å¤åˆ¶é…ç½®æ–‡ä»¶
echo "ğŸ“ å¤åˆ¶é…ç½®æ–‡ä»¶..."
cp "$SCRIPT_DIR/custom_models.json" "$TARGET_DIR/zen_tools/"

# å¤åˆ¶.envæ–‡ä»¶ï¼ˆåŒ…å«APIå¯†é’¥ï¼‰
if [ -f "$SCRIPT_DIR/.env" ]; then
    echo "ğŸ”‘ å¤åˆ¶.envæ–‡ä»¶..."
    cp "$SCRIPT_DIR/.env" "$TARGET_DIR/zen_tools/"
else
    echo "âš ï¸  è­¦å‘Š: .envæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½ å¯èƒ½éœ€è¦æ‰‹åŠ¨åˆ›å»ºå¹¶æ·»åŠ APIå¯†é’¥"
fi

# åˆ›å»ºç®€åŒ–çš„zen_ai.pyæ¥å£
echo "ğŸ åˆ›å»ºzen_ai.pyæ¥å£..."
cat > "$TARGET_DIR/zen_ai.py" << 'EOF'
#!/usr/bin/env python3
"""
Zen AI - ç®€åŒ–çš„å¤šæ¨¡å‹AIæ¥å£
æä¾›å¯¹O3å’ŒGeminiæ¨¡å‹çš„ç›´æ¥è®¿é—®
"""

import json
import requests
import os
from pathlib import Path
from typing import Optional, Dict, Any, List

class ZenAI:
    def __init__(self):
        self.config_path = Path(__file__).parent / "zen_tools" / "custom_models.json"
        self.providers = self._load_config()
        
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½æ¨¡å‹é…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return {p['name']: p for p in config['providers']}
        except Exception as e:
            print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
            return {}
    
    def models(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        available_models = []
        for provider_name, provider in self.providers.items():
            for model in provider['models']:
                available_models.append(model['id'])
                print(f"ğŸ¤– {model['id']} - {model['name']}")
                print(f"   ğŸ“ {model['description']}")
                print(f"   ğŸ”¢ ä¸Šä¸‹æ–‡: {model['context_window']:,} tokens")
                print()
        return available_models
    
    def _find_model_provider(self, model_id: str) -> Optional[Dict[str, Any]]:
        """æŸ¥æ‰¾æ¨¡å‹å¯¹åº”çš„æä¾›å•†"""
        for provider in self.providers.values():
            for model in provider['models']:
                if model['id'] == model_id:
                    return provider
        return None
    
    def chat(self, prompt: str, model: str = 'gemini-2.5-flash') -> str:
        """ä¸æŒ‡å®šæ¨¡å‹å¯¹è¯"""
        provider = self._find_model_provider(model)
        if not provider:
            return f"âŒ æ¨¡å‹ {model} ä¸å¯ç”¨"
        
        try:
            headers = {
                'Authorization': f"Bearer {provider['api_key']}",
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': model,
                'messages': [
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 4000,
                'temperature': 0.7
            }
            
            response = requests.post(
                f"{provider['api_url']}/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                return f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}"
                
        except Exception as e:
            return f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}"

# ä¾¿æ·å‡½æ•°
def ask_gemini(prompt: str, model: str = 'gemini-2.5-flash') -> str:
    """ä½¿ç”¨Geminiæ¨¡å‹å¿«é€Ÿé—®ç­”"""
    ai = ZenAI()
    return ai.chat(prompt, model)

def ask_o3(prompt: str, model: str = 'o3-mini') -> str:
    """ä½¿ç”¨O3æ¨¡å‹è¿›è¡Œæ¨ç†"""
    ai = ZenAI()
    return ai.chat(prompt, model)

def list_models() -> List[str]:
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    ai = ZenAI()
    return ai.models()

# ä¸»ç¨‹åº - æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
if __name__ == "__main__":
    print("ğŸš€ Zen AI æ¨¡å‹ç³»ç»Ÿ")
    print("=" * 50)
    
    ai = ZenAI()
    if not ai.providers:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹é…ç½®")
        print("   è¯·ç¡®ä¿ zen_tools/custom_models.json æ–‡ä»¶å­˜åœ¨")
        exit(1)
    
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
    models = ai.models()
    
    print(f"âœ… å…±æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹")
    print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
    print("from zen_ai import ask_gemini, ask_o3")
    print("answer = ask_gemini('ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ?')")
    print("solution = ask_o3('è®¾è®¡ä¸€ä¸ªæ’åºç®—æ³•')")
EOF

# åˆ›å»ºä½¿ç”¨ç¤ºä¾‹
echo "ğŸ“„ åˆ›å»ºä½¿ç”¨ç¤ºä¾‹..."
cat > "$TARGET_DIR/zen_ai_example.py" << 'EOF'
#!/usr/bin/env python3
"""
Zen AI ä½¿ç”¨ç¤ºä¾‹ - å±•ç¤ºå¦‚ä½•åœ¨G-codeé¡¹ç›®ä¸­ä½¿ç”¨AIæ¨¡å‹
"""

from zen_ai import ZenAI, ask_gemini, ask_o3

def basic_usage():
    """åŸºæœ¬ç”¨æ³•ç¤ºä¾‹"""
    print("=== åŸºæœ¬ç”¨æ³• ===")
    
    # å¿«é€Ÿé—®ç­”
    answer = ask_gemini("ä»€ä¹ˆæ˜¯CNCç¼–ç¨‹?")
    print(f"Geminiå›ç­”: {answer[:200]}...")
    
    # å¤æ‚æ¨ç†
    solution = ask_o3("è®¾è®¡ä¸€ä¸ªGä»£ç ä¼˜åŒ–æ€è·¯")
    print(f"O3æ–¹æ¡ˆ: {solution[:200]}...")

def advanced_usage():
    """é«˜çº§ç”¨æ³•ç¤ºä¾‹"""
    print("\n=== é«˜çº§ç”¨æ³• ===")
    
    ai = ZenAI()
    
    # ä½¿ç”¨ç‰¹å®šæ¨¡å‹
    response = ai.chat(
        "åˆ†æä»¥ä¸‹Gä»£ç çš„æ€§èƒ½: G01 X10 Y20 F100", 
        model='gemini-2.5-pro'
    )
    print(f"æ·±åº¦åˆ†æ: {response[:200]}...")
    
    # å¯¹æ¯”ä¸åŒæ¨¡å‹
    models_to_test = ['gemini-2.5-flash', 'o3-mini']
    question = "ä»€ä¹ˆæ˜¯æ•°æ§åŠ å·¥?"
    
    for model in models_to_test:
        response = ai.chat(question, model)
        print(f"\n{model} å›ç­”:")
        print(response[:150] + "...")

if __name__ == "__main__":
    # é¦–å…ˆåˆ—å‡ºå¯ç”¨æ¨¡å‹
    print("ğŸ” æ£€æŸ¥å¯ç”¨æ¨¡å‹...")
    from zen_ai import list_models
    models = list_models()
    
    if models:
        print(f"\nâœ… å‘ç° {len(models)} ä¸ªæ¨¡å‹ï¼Œå¼€å§‹æµ‹è¯•...")
        basic_usage()
        advanced_usage()
    else:
        print("âŒ æ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥é…ç½®")
EOF

# åˆ›å»ºrequirements.txtï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
if [ ! -f "$TARGET_DIR/requirements.txt" ]; then
    echo "ğŸ“¦ åˆ›å»ºrequirements.txt..."
    cat > "$TARGET_DIR/requirements.txt" << 'EOF'
requests>=2.28.0
EOF
else
    # æ£€æŸ¥æ˜¯å¦å·²åŒ…å«requests
    if ! grep -q "requests" "$TARGET_DIR/requirements.txt"; then
        echo "requests>=2.28.0" >> "$TARGET_DIR/requirements.txt"
        echo "ğŸ“¦ æ·»åŠ requestsä¾èµ–åˆ°ç°æœ‰requirements.txt"
    fi
fi

# è®¾ç½®æ‰§è¡Œæƒé™
chmod +x "$TARGET_DIR/zen_ai.py"
chmod +x "$TARGET_DIR/zen_ai_example.py"

echo ""
echo "âœ… å¤åˆ¶å®Œæˆï¼"
echo ""
echo "ğŸ“‹ å·²åˆ›å»ºçš„æ–‡ä»¶:"
echo "   ğŸ“„ $TARGET_DIR/zen_ai.py - ä¸»è¦AIæ¥å£"
echo "   ğŸ“„ $TARGET_DIR/zen_ai_example.py - ä½¿ç”¨ç¤ºä¾‹"
echo "   ğŸ“ $TARGET_DIR/zen_tools/custom_models.json - æ¨¡å‹é…ç½®
   ğŸ“ $TARGET_DIR/zen_tools/.env - APIå¯†é’¥é…ç½®"
echo ""
echo "ğŸ”¬ æµ‹è¯•å®‰è£…:"
echo "   cd \"$TARGET_DIR\""
echo "   python zen_ai.py"
echo ""
echo "ğŸ’¡ æ—¥å¸¸ä½¿ç”¨:"
echo "   from zen_ai import ask_gemini, ask_o3"
echo "   answer = ask_gemini('ä½ çš„é—®é¢˜')"
echo ""
echo "ğŸ‰ é›†æˆå®Œæˆï¼å¯ä»¥åœ¨G-codeé¡¹ç›®ä¸­ä½¿ç”¨Zen AIäº†ï¼"